{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks(CNNs)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Convolutional Neural Networks are a type of Deep Learning Algorithm that is used for image recognition and classification. They are also used for other tasks like object detection, image generation, etc. \n",
    "\n",
    "卷积神经网络是一种用于图像识别和分类的深度学习算法。它们也用于其他任务,如目标检测、图像生成等。\n",
    "\n",
    "CNNs are inspired by the structure of the human brain. The brain has a visual cortex that is responsible for processing visual information. The visual cortex has a small region of cells that are sensitive to specific regions of the visual field. This region is called the receptive field. The receptive fields of different cells overlap to cover the entire visual field. The cells in the visual cortex are sensitive to different features of the visual field like edges, colors, etc.\n",
    "\n",
    "CNN受到人脑结构的启发。人脑有一个负责处理视觉信息的视觉皮层。视觉皮层有一个对视觉场的特定区域敏感的小区域。这个区域被称为感受野。不同细胞的感受野重叠,覆盖整个视觉场。视觉皮层的细胞对视觉场的不同特征敏感,如边缘、颜色等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs utilize a special type of layer, aptly named a convolutional layer, that makes them well-positioned to learn from image and image-like data. Regarding image data, CNNs can be used for many different computer vision tasks, such as image processing, classification, segmentation, and object detection.\n",
    "\n",
    "CNN 利用一种特殊类型的层,即卷积层,使其能够很好地学习图像和类似图像的数据。在图像数据方面,CNN 可用于许多不同的计算机视觉任务,如图像处理、分类、分割和物体检测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolutional layers are the foundation of CNN, as they contain the learned kernels (weights), which extract features that distinguish different images from one another—this is what we want for classification! As you interact with the convolutional layer, you will notice links between the previous layers and the convolutional layers. Each link represents a unique kernel, which is used for the convolution operation to produce the current convolutional neuron's output or activation map.\n",
    "\n",
    "卷积层是 CNN 的基础,因为它们包含了学习到的核（权重）,这些核可以提取出区分不同图像的特征--这正是我们想要的分类功能！当你与卷积层交互时,你会注意到前几层与卷积层之间的链接。每个链接都代表一个独特的内核,用于卷积操作,生成当前卷积神经元的输出或激活图。\n",
    "\n",
    "![](https://img-blog.csdnimg.cn/f2fab1646d25417e98c6b23480bf525a.gif#pic_center)\n",
    "\n",
    "The convolutional neuron performs an elementwise dot product with a unique kernel and the output of the previous layer's corresponding neuron. This will yield as many intermediate results as there are unique kernels. The convolutional neuron is the result of all of the intermediate results summed together with the learned bias.\n",
    "\n",
    "卷积神经元与唯一的内核和上一层相应神经元的输出进行元素点乘。有多少个独特的内核,就会产生多少个中间结果。卷积神经元是所有中间结果与学习偏置相加的结果。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://poloclub.github.io/cnn-explainer/assets/figures/convlayer_overview_demo.gif)\n",
    "\n",
    "For example, let's look at the first convolutional layer in the Tiny VGG architecture above. Notice that there are 10 neurons in this layer, but only 3 neurons in the previous layer. In the Tiny VGG architecture, convolutional layers are fully-connected, meaning each neuron is connected to every other neuron in the previous layer. Focusing on the output of the topmost convolutional neuron from the first convolutional layer, we see that there are 3 unique kernels when we hover over the activation map.\n",
    "\n",
    "例如,让我们来看看上述 Tiny VGG 架构中的第一个卷积层。请注意,这一层有 10 个神经元,而上一层只有 3 个神经元。在 Tiny VGG 架构中,卷积层是全连接的,这意味着每个神经元都与上一层中的其他神经元相连。我们将注意力集中在第一个卷积层最顶端卷积神经元的输出上,当我们将鼠标悬停在激活图上时,会发现有 3 个独特的内核。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of these kernels is a hyper-parameter specified by the designers of the network architecture. In order to produce the output of the convolutional neuron (activation map), we must perform an elementwise dot product with the output of the previous layer and the unique kernel learned by the network. In TinyVGG, the dot product operation uses a stride of 1, which means that the kernel is shifted over 1 pixel per dot product, but this is a hyperparameter that the network architecture designer can adjust to better fit their dataset. We must do this for all 3 kernels, which will yield 3 intermediate results.\n",
    "\n",
    "这些核的大小是网络架构设计人员指定的一个超参数。为了生成卷积神经元的输出（激活图）,我们必须将上一层的输出与网络学习到的唯一核进行元素点乘。在 TinyVGG 中，点乘运算使用的跨距为 1，这意味着每次点乘时，内核都会移动 1 个像素，但这是一个超参数，网络架构设计师可以对其进行调整，以更好地适应自己的数据集。我们必须对所有 3 个内核都这样做，这将产生 3 个中间结果。\n",
    "\n",
    "![](https://poloclub.github.io/cnn-explainer/assets/figures/convlayer_detailedview_demo.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, an elementwise sum is performed containing all 3 intermediate results along with the bias the network has learned. After this, the resulting 2-dimensional tensor will be the activation map viewable on the interface above for the topmost neuron in the first convolutional layer. This same operation must be applied to produce each neuron's activation map.\n",
    "\n",
    "然后，再对所有 3 个中间结果以及网络学习到的偏置进行元素相加。之后，得到的二维张量将是第一个卷积层最顶层神经元的激活图，可在上述界面查看。在绘制每个神经元的激活图时，都必须执行相同的操作。\n",
    "\n",
    "With some simple math, we are able to deduce that there are 3 x 10 = 30 unique kernels, each of size 3x3, applied in the first convolutional layer. The connectivity between the convolutional layer and the previous layer is a design decision when building a network architecture, which will affect the number of kernels per convolutional layer. \n",
    "\n",
    "通过一些简单的数学运算，我们可以推断出第一卷积层中有 3 x 10 = 30 个独特的内核，每个内核的大小为 3x3。卷积层和上一层之间的连接是构建网络架构时的一个设计决定，这将影响每个卷积层的内核数量。！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study MNIST-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a084c7ff70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data preprocessing \n",
    "# 数据预处理\n",
    "# transfer the training data to torch type\n",
    "# 将training data转化成torch能够使用的DataLoader，这样可以方便使用batch进行训练\n",
    "\n",
    "# set the seed for the random number generator\n",
    "# reproducible 将随机数生成器的种子设置为固定值，这样，当调用时torch.rand(x)，结果将可重现\n",
    " \n",
    "torch.manual_seed(1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "# 超参数\n",
    "\n",
    "# EPOCH: the number of times the training data is used for training\n",
    "# 训练迭代次数\n",
    "EPOCH = 1 \n",
    "\n",
    "# BATCH_SIZE: the number of samples in one batch\n",
    "# 分块送入训练器\n",
    "BATCH_SIZE = 50 \n",
    "\n",
    "# TIME_STEP: the number of time steps in one batch\n",
    "# 学习率 learning rate\n",
    "LR = 0.001 \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist/', # 保存位置 若没有就新建\n",
    "    train=True, # training set\n",
    "    transform=torchvision.transforms.ToTensor(), # \n",
    "    # converts a PIL.Image or numpy.ndarray to torch.FloatTensor(C*H*W) in range(0.0,1.0)\n",
    "    download=True\n",
    ")\n",
    " \n",
    "test_data = torchvision.datasets.MNIST(root='./MNIST/')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SBH\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "c:\\Users\\SBH\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "# 如果是普通的Tensor数据，想使用 torch_dataset = data.TensorDataset(data_tensor=x, target_tensor=y)\n",
    "# 将Tensor转换成torch能识别的dataset\n",
    "# 批训练， 50 samples, 1 channel, 28*28, (50, 1, 28 ,28)\n",
    "train_loader = data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 使用torch.no_grad()处理测试数据\n",
    "with torch.no_grad():\n",
    "    test_x = torch.unsqueeze(test_data.test_data, dim=1).type(torch.FloatTensor)[:2000] / 255.\n",
    "\n",
    "\n",
    " \n",
    "test_y = test_data.test_labels[:2000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# 定义网络结构\n",
    "# 1）class CNN需要·继承·Module \n",
    "# 2）需要·调用·父类的构造方法：super(CNN, self).__init__()\n",
    "# 3）在Pytorch中激活函数Relu也算是一层layer\n",
    "# 4）需要·实现·forward()方法，用于网络的前向传播，而反向传播只需要·调用·Variable.backward()即可。\n",
    "# 输入的四维张量[N, C, H, W]\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # nn.Sequential一个有序的容器，神经网络模块将按照在传入构造器的顺序依次被添加到计算图中执行，\n",
    "        # 同时以神经网络模块为元素的有序字典也可以作为传入参数\n",
    "        # nn.Conv2d 二维卷积 先实例化再使用 在Pytorch的nn模块中，它是不需要你手动定义网络层的权重和偏置的\n",
    "        self.conv1 = nn.Sequential( #input shape (1,28,28)\n",
    "            nn.Conv2d(in_channels=1, #input height 必须手动提供 输入张量的channels数\n",
    "                      out_channels=16, #n_filter 必须手动提供 输出张量的channels数\n",
    "                      kernel_size=5, #filter size 必须手动提供 卷积核的大小 \n",
    "                      # 如果左右两个数不同，比如3x5的卷积核，那么写作kernel_size = (3, 5)，注意需要写一个tuple，而不能写一个列表（list）\n",
    "                      stride=1, #filter step 卷积核在图像窗口上每次平移的间隔，即所谓的步长\n",
    "                      padding=2 #con2d出来的图片大小不变 Pytorch与Tensorflow在卷积层实现上最大的差别就在于padding上\n",
    "            ), # output shape (16,28,28) 输出图像尺寸计算公式是唯一的 # O = （I - K + 2P）/ S +1\n",
    "            nn.ReLU(), # 分段线性函数，把所有的负值都变为0，而正值不变，即单侧抑制\n",
    "            nn.MaxPool2d(kernel_size=2) #2x2采样，28/2=14，output shape (16,14,14) maxpooling有局部不变性而且可以提取显著特征的同时降低模型的参数，从而降低模型的过拟合\n",
    "        ) \n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16, 32, 5, 1, 2), #output shape (32,7,7)\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.MaxPool2d(2))\n",
    "        # 因上述几层网络处理后的output为[32,7,7]的tensor，展开即为7*7*32的一维向量，接上一层全连接层，最终output_size应为10，即识别出来的数字总类别数\n",
    "        # 在二维图像处理的任务中，全连接层的输入与输出一般都设置为二维张量，形状通常为[batch_size, size]\n",
    "        self.out = nn.Linear(32*7*7, 10) # 全连接层 7*7*32, num_classes\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # 卷一次\n",
    "        x = self.conv2(x) # 卷两次\n",
    "        x = x.view(x.size(0), -1) #flat (batch_size, 32*7*7) \n",
    "        # 将前面多维度的tensor展平成一维 x.size(0)指batchsize的值\n",
    "        # view()函数的功能根reshape类似，用来转换size大小\n",
    "        output = self.out(x) # fc out全连接层 分类器\n",
    "        return output\n",
    "# 定义网络结构\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 查看网络结构\n",
    "cnn = CNN()\n",
    "print(cnn) # 使用print(cnn)可以看到网络的结构详细信息，可以看到ReLU()也是一层layer\n",
    "# 查看网络结构\n",
    " \n",
    " \n",
    "# 训练 需要特别指出的是记得每次反向传播前都要清空上一次的梯度，optimizer.zero_grad()\n",
    "# optimizer 可以指定程序优化特定的选项，例如学习速率，权重衰减等\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR) # torch.optim是一个实现了多种优化算法的包\n",
    " \n",
    "# loss_fun CrossEntropyLoss 交叉熵损失\n",
    "# 信息量：它是用来衡量一个事件的不确定性的；一个事件发生的概率越大，不确定性越小，则它所携带的信息量就越小。\n",
    "# 熵：它是用来衡量一个系统的混乱程度的，代表一个系统中信息量的总和；信息量总和越大，表明这个系统不确定性就越大。\n",
    "# 交叉熵：它主要刻画的是实际输出（概率）与期望输出（概率）的距离，也就是交叉熵的值越小，两个概率分布就越接近\n",
    "loss_func = nn.CrossEntropyLoss() # 该损失函数结合了nn.LogSoftmax()和nn.NLLLoss()两个函数 适用于分类\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "for epoch in range(EPOCH):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        batch_x = Variable(x)\n",
    "        batch_y = Variable(y)\n",
    "        output = cnn(batch_x) # 输入训练数据\n",
    "        loss = loss_func(output, batch_y) # 计算误差 #　实际输出，　期望输出\n",
    "        optimizer.zero_grad() # 清空上一次梯度\n",
    "        loss.backward() # 误差反向传递 只需要调用.backward()即可\n",
    "        optimizer.step() # cnn的优化器参数更新\n",
    "# 训练\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4] prediction number\n",
      "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4]) real number\n"
     ]
    }
   ],
   "source": [
    "# 预测结果\n",
    "# cnn.eval()\n",
    "test_output = cnn(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "# torch.max(input, dim)函数  \n",
    "# torch.max(test_output, 1)[1]  取出来indices 每行最大值的索引\n",
    "# 输入 input是softmax函数输出的一个tensor  \n",
    "# 输入 dim是max函数索引的维度0/1，0是每列的最大值，1是每行的最大值\n",
    "# 输出 函数会返回两个tensor，第一个tensor是每行的最大值；第二个tensor是每行最大值的索引。\n",
    "# squeeze()函数的功能是：从矩阵shape中，去掉维度为1的。例如一个矩阵是的shape是（5， 1），使用过这个函数后，结果为（5，）。\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10], 'real number')\n",
    "# 预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study MNIST-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the global variables\n",
    "# 初始化全局变量\n",
    "\n",
    "BATCH_SIZE = 1                     # DataLoader每批次读取样本数\n",
    "IMG_SIZE = (32, 32)                # 标准化图像尺寸\n",
    "NORM_MEAN = [0.485, 0.456, 0.406]  # Image-net大赛中使用的图像数据均值\n",
    "NORM_STD = [0.229, 0.224, 0.225]   # Image-net大赛中使用的图像数据标准差\n",
    "LR = 0.05                          # 网络的学习率，即迭代步长\n",
    "MOMENTUM = 0.2                     # 网络学习动量，即在每次训练中保持此比例的参数不变\n",
    "MAX_EPOCH = 60                     # 最大训练轮数，一轮是把所有训练样本跑一遍\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision.transforms import transforms\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder 编码器\n",
    "encoder = {\n",
    "        \"0\":torch.tensor([1.,0.,0.,0.,0.,0.,0.,0.,0.,0.]),\n",
    "        \"1\":torch.tensor([0.,1.,0.,0.,0.,0.,0.,0.,0.,0.]),\n",
    "        \"2\":torch.tensor([0.,0.,1.,0.,0.,0.,0.,0.,0.,0.]),\n",
    "        \"3\":torch.tensor([0.,0.,0.,1.,0.,0.,0.,0.,0.,0.]),\n",
    "        \"4\":torch.tensor([0.,0.,0.,0.,1.,0.,0.,0.,0.,0.]),\n",
    "        \"5\":torch.tensor([0.,0.,0.,0.,0.,1.,0.,0.,0.,0.]),\n",
    "        \"6\":torch.tensor([0.,0.,0.,0.,0.,0.,1.,0.,0.,0.]),\n",
    "        \"7\":torch.tensor([0.,0.,0.,0.,0.,0.,0.,1.,0.,0.]),\n",
    "        \"8\":torch.tensor([0.,0.,0.,0.,0.,0.,0.,0.,1.,0.]),\n",
    "        \"9\":torch.tensor([0.,0.,0.,0.,0.,0.,0.,0.,0.,1.]),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NumDataset(Dataset):\n",
    "    '''\n",
    "    用于读取图像数据，包括训练数据和测试数据，并按指定方式（如有）做数据转换。\n",
    "    \n",
    "    Parameters of init\n",
    "    ----------\n",
    "    dataDir : String\n",
    "        给出相对当前PYTHONPATH目录的数据地址。\n",
    "    transformer : \n",
    "        图像数据转换器，包含了对图像数据需要做的一些转换。默认为空。\n",
    "    '''\n",
    "    def __init__(self, dataDir, transformer=None):\n",
    "        self.dataInfo = []      # 初始化一个图像数据信息元组列表\n",
    "        # 遍历每个图片文件名\n",
    "        for item in os.listdir(dataDir):\n",
    "            label = item[1]     # 每张图片文件名的第二个字符为该图片的标签\n",
    "            imgPath = dataDir + \"/\" + item  # 拼装成具体图片文件的地址\n",
    "            self.dataInfo.append((imgPath, label)) # 一个图片地址对应其标签形成一个元组\n",
    "        self.transformer = transformer\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        根据索引来获取一条具体数据的魔法。设有该类对象nd,运行nd[index]时即运行此魔法。\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        index : int\n",
    "            代表数据元组列表种的序号。\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        img : Image(default)\n",
    "            代表该条图片的RGB数据。具体变量类型可能会由数据转换器改变。\n",
    "        encoder[label] : Tensor\n",
    "            代表该条图片数据对应的标签编码结果。\n",
    "        '''\n",
    "        imgPath, label = self.dataInfo[index]    # 按序号获取图片地址和标签\n",
    "        img = Image.open(imgPath).convert('RGB') # 按路径获取图片RGB数据\n",
    "        if self.transformer is not None:\n",
    "            img = self.transformer(img)          # 用指定方式对图像数据做转换\n",
    "        \n",
    "        return img, encoder[label]\n",
    "    \n",
    "    def __len__(self):\n",
    "        '''\n",
    "        使得“len(该类对象)”可以正常运行。\n",
    "        '''\n",
    "        return len(self.dataInfo)\n",
    "\n",
    "# 指定样本目录\n",
    "sampleRootDir = \"./numberSample\"                  # 指定样本根目录\n",
    "trainDir = sampleRootDir + \"/\" + \"train\"          # 指定训练样本目录\n",
    "testDir = sampleRootDir + \"/\" + \"test\"            # 指定测试样本目录\n",
    "\n",
    "# 指定图像数据转换方式\n",
    "transformer = transforms.Compose([\n",
    "        transforms.Resize(IMG_SIZE),              # 将图片大小固定为32*32像素\n",
    "        transforms.ToTensor(),                    # 转化成Tensor类型数据\n",
    "        transforms.Normalize(NORM_MEAN, NORM_STD) # 对图像数据归一化\n",
    "        ])\n",
    "\n",
    "# 实例化数据集\n",
    "trainData = NumDataset(trainDir, transformer)     # 实例化训练数据集对象\n",
    "testData = NumDataset(testDir, transformer)       # 实例化测试数据集对象\n",
    "\n",
    "# 实例化数据加载器\n",
    "trainLoader = DataLoader(                         # 训练数据加载器\n",
    "        dataset = trainData,                      # 指定读取的数据集\n",
    "        batch_size = BATCH_SIZE,                  # 指定每批次读取样本数\n",
    "        shuffle = True                            # 打乱样本顺序\n",
    "        )\n",
    "testLoader = DataLoader(                          # 测试数据加载器\n",
    "        dataset = testData,                       # 指定读取的数据集\n",
    "        batch_size = BATCH_SIZE,                  # 指定每批次读取样本数\n",
    "        shuffle = True                            # 打乱样本顺序\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN network\n",
    "# 构造卷积神经网络\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    '''\n",
    "    一种卷积神经网络。\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        定义网络结构。\n",
    "        '''\n",
    "        # 使用其父类来初始化\n",
    "        super(LeNet, self).__init__()\n",
    "    \n",
    "        # 构造第一个卷积层\n",
    "        self.conv1 = nn.Conv2d(\n",
    "                in_channels=3,   # 指定入参数据的通道数。RGB图像是三个图层，即3通道\n",
    "                out_channels=6,  # 指定该卷积层的输出通道数，即该层卷积核个数\n",
    "                kernel_size=5,   # 指定卷积核尺寸，此时为5*5\n",
    "                stride=1         # 指定卷积步长，即每做一次卷积后，卷积核平移一个像素\n",
    "                )\n",
    "        '''\n",
    "        1、由于2维卷积核是长宽都是5，则会使得卷积后的结果在横纵方向上都少4个像素，因此\n",
    "           卷积后的各图层尺寸由原来的32*32（IMG_SIZE）变成28*28。\n",
    "        2、由于卷积核个数是6，则会使卷积后的图层变成6个，即数据尺寸为28*28*6。\n",
    "        3、卷积后会做激活，而激活并不改变数据尺寸。\n",
    "        4、每次激活后做2*2尺寸的2步长池化，则数据尺寸变为14*14*6。\n",
    "        '''\n",
    "        \n",
    "        # 构建第二个卷积层（使池化后图像尺寸变为5*5*16）\n",
    "        self.conv2 = nn.Conv2d(\n",
    "                in_channels=6,   # 指定入参数据的通道数。即上一层输出的图层数\n",
    "                out_channels=16, # 指定该卷积层的输出通道数，即该层卷积核个数\n",
    "                kernel_size=5,   # 指定卷积核尺寸，此时为5*5\n",
    "                stride=1         # 指定卷积步长，即每做一次卷积后，卷积核平移一个像素\n",
    "                )\n",
    "        \n",
    "        # 构建第一个全链接层（即普通BP网络的输入加权运算）\n",
    "        self.fc1 = nn.Linear(\n",
    "                in_features=5*5*16, # 指定入参个数。即上一个卷积池化后的图像像素数量\n",
    "                out_features=120,   # 指定出参个数。\n",
    "                )\n",
    "        \n",
    "        # 构建第二个全链接层\n",
    "        self.fc2 = nn.Linear(\n",
    "                in_features=120,    # 指定入参个数。即上一层出参个数\n",
    "                out_features=84,    # 指定出参个数。\n",
    "                )\n",
    "        \n",
    "        # 构建最后一个全链接层\n",
    "        self.fc3 = nn.Linear(\n",
    "                in_features=84,     # 指定入参个数。即上一层出参个数\n",
    "                out_features=10,    # 指定出参个数。分别对应10个数字\n",
    "                )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        定义网络的前向传播运算过程。\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : Tensor(4D)\n",
    "            一个尺寸为batchsize*IMG_SIZE*3的4阶张量,代表一个批次的RGB图像数据。\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        out : Tensor(2D)\n",
    "            一个尺寸为batchsize*10的2阶张量,代表该批次各图像的识别结果为各数字的概率。\n",
    "        '''\n",
    "        # 经过两轮卷积、激活、池化\n",
    "        out = self.conv1(x)         # 由第一个卷积层对入参做卷积运算\n",
    "        out = F.relu(out)           # 对卷积结果做激活运算。relu(x)=max(x, 0)\n",
    "        out = F.max_pool2d(         # 对激活结果做二维最大值池化\n",
    "                input=out,          # 激活结果作为池化输入\n",
    "                kernel_size=2,      # 池化尺寸。即在一个2*2的像素区域中取最大值\n",
    "                stride=2            # 池化步长。\n",
    "                )\n",
    "        out = self.conv2(out)                                  # 第二轮卷积\n",
    "        out = F.relu(out)                                      # 激活\n",
    "        out = F.max_pool2d(input=out, kernel_size=2, stride=2) # 池化\n",
    "        \n",
    "        # 将当前该批次中的每个3阶张量数据展开成1阶\n",
    "        out = out.view(out.size(0), -1)\n",
    "        \n",
    "        # 经过三层BP网络\n",
    "        out = self.fc1(out)                # 经过第一层BP加权运算\n",
    "        out = F.relu(out)                  # 对加权运算结果做激活\n",
    "        out = self.fc2(out)                # 经过第二层BP加权运算\n",
    "        out = F.relu(out)                  # 对加权运算结果做激活\n",
    "        out = self.fc3(out)                # 经过第三层BP加权运算\n",
    "        out = F.softmax(out, dim=1)        # 对加权运算结果做激活得到最终输出\n",
    "        '''\n",
    "        1、输出有10个神经元,希望的结果是识别出输入图像是数字几,则第几个神经元输出1,其他输出0。\n",
    "        2、max函数的效果是对各输出神经元取值做比较,最大的赋1,其余赋0。但如此则无法渐进对比损失大小了。\n",
    "        3、softmax的效果是根据各输出神经元取值大小赋予不同的概率值,原值越大概率越大,各输出的概率和为1。\n",
    "        4、dim=1使得每组输出都排成一行。\n",
    "        '''\n",
    "        \n",
    "        return out\n",
    "      \n",
    "    def initWeight(self):\n",
    "        '''\n",
    "        初始化网络各待训练权重值。\n",
    "        '''\n",
    "        # 遍历网络的各层对象\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):    # 如果是卷积层\n",
    "                # 使用正态分布随机数对该层卷积核各权重做初始化\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                # 使用0对该层卷积核各偏移量做初始化\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):  # 如果是全连接层\n",
    "                # 使用标准正态分布随机数对该层卷积核各权重做初始化\n",
    "                nn.init.normal_(m.weight.data, mean=0, std=0.1)\n",
    "                # 使用0对该层卷积核各偏移量做初始化\n",
    "                m.bias.data.zero_()\n",
    "            \n",
    "# 实例化网络对象，并初始化网络参数\n",
    "net = LeNet()\n",
    "net.initWeight()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 训练并保存网络\n",
    "# =============================================================================\n",
    "import torch.optim as optim\n",
    "\n",
    "# 实例化交叉熵损失计算器\n",
    "losses = nn.CrossEntropyLoss()\n",
    "'''\n",
    "交叉熵损失函数：\n",
    "CrossEntropyLoss = -1/N sum_i(sum_c=1^M(y_ic*log(p_ic)))\n",
    "其中，N为样本数量；M为分类数；y_ic表示如果第i个样本属于c类，则为1，否则为0；p_ic表示预\n",
    "测第i个样本属于c类的概率。\n",
    "'''\n",
    "\n",
    "# 实例化优化器\n",
    "optimizer = optim.SGD(\n",
    "        params=net.parameters(), # 指定网络所有参数（包括各权重和偏置）为待优化参数\n",
    "        lr=LR,                   # 指定网络的学习率\n",
    "        momentum=MOMENTUM,       # 学习动量，即每次训练中保持此比例的参数值不变\n",
    "        )\n",
    "\n",
    "# 开始训练\n",
    "epoch = 0                        # 初始化训练轮数\n",
    "while epoch < MAX_EPOCH:\n",
    "    \n",
    "    net.train()                  # 将网络切换到训练模式\n",
    "    \n",
    "    totalSampleNum = 0           # 初始化总训练样本个数\n",
    "    correctSampleNum = 0         # 初始化识别正确的样本个数\n",
    "    \n",
    "    # 逐批次训练\n",
    "    for i, data in enumerate(trainLoader):\n",
    "        '''\n",
    "        i ：训练批次号。\n",
    "        data : 一批次的训练数据，即一批Dataset。\n",
    "        '''\n",
    "        \n",
    "        # 获取当前批次的训练数据\n",
    "        img, label = data\n",
    "        '''\n",
    "        img : 由各Dataset中的img构成的四阶张量。\n",
    "        label : 由各Dataset中的label构成的一个元组。\n",
    "        '''\n",
    "        totalSampleNum += label.shape[0]   # 更新总样本个数\n",
    "        \n",
    "        # 获取当前这批训练数据的网络运算结果\n",
    "        output = net(img)\n",
    "        '''\n",
    "        1、等价于net.forward(img)，且仅等价于调用\"forward\"这个函数名。\n",
    "        2、各运算结果是一个含十个元素的张量，其和为1。\n",
    "        '''\n",
    "        # 输出概率最大的那个神经元位置即为识别的数字值\n",
    "        res = torch.max(output.data, 1).indices         # 网络识别结果\n",
    "        real = torch.max(label.data, 1).indices         # 真实结果\n",
    "        correctSampleNum += (res == real).sum().item()  # 更新识别正确的样本个数\n",
    "\n",
    "        # 计算该批训练结果的总交叉熵损失\n",
    "        loss = losses(output, label)\n",
    "                \n",
    "        # 网络（各待优化参数）梯度清零\n",
    "        net.zero_grad()\n",
    "        \n",
    "        # 反向传播重新生成网络梯度\n",
    "        loss.backward()\n",
    "        \n",
    "        # 按梯度下降方向更新网络参数\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 统计该轮训练效果\n",
    "    print(f\"第{epoch}轮的训练准确率为{correctSampleNum/totalSampleNum}\")\n",
    "    \n",
    "    epoch += 1\n",
    "\n",
    "# 保存网络\n",
    "torch.save(net.state_dict(), './numberSample/trainedCNN.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./numberSample/trainedCNN.pth') # 实例化加载点\n",
    "mynet = LeNet()                                          # 实例化一个LeNet\n",
    "mynet.load_state_dict(checkpoint)                        # 从加载点加载网络参数\n",
    "print(mynet)                                             # 查看网络结构\n",
    "\n",
    "# 逐批次测试\n",
    "totalTestNum = 0                                    # 初始化总测试样本个数\n",
    "correctTestNum = 0                                  # 初始化识别正确的样本个数\n",
    "for i, data in enumerate(testLoader):\n",
    "    '''\n",
    "    i ：测试批次号。\n",
    "    data : 一批次测试数据。\n",
    "    '''\n",
    "    \n",
    "    img, label = data                               # 获取当前批次的测试数据\n",
    "    output = mynet(img)                             # 得到网络输出\n",
    "    res = torch.max(output.data, 1).indices         # 网络识别结果\n",
    "    real = torch.max(label.data, 1).indices         # 真实结果\n",
    "    totalTestNum += label.shape[0]                  # 更新总测试样本个数\n",
    "    correctTestNum += (res == real).sum().item()    # 更新识别正确的测试样本个数\n",
    "    print(f\"真实数字为{real}\")                       # 打印当前样本真实数字\n",
    "    print(f\"网络识别为{res}\")                        # 打印当前识别结果\n",
    "    print(\"***********\")\n",
    "\n",
    "# 打印测试统计结果\n",
    "print(f\"测试准确率为{correctTestNum/totalTestNum}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
