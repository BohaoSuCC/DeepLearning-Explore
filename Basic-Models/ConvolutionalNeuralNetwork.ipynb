{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks(CNNs)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Convolutional Neural Networks are a type of Deep Learning Algorithm that is used for image recognition and classification. They are also used for other tasks like object detection, image generation, etc. \n",
    "\n",
    "卷积神经网络是一种用于图像识别和分类的深度学习算法。它们也用于其他任务，如目标检测、图像生成等。\n",
    "\n",
    "CNNs are inspired by the structure of the human brain. The brain has a visual cortex that is responsible for processing visual information. The visual cortex has a small region of cells that are sensitive to specific regions of the visual field. This region is called the receptive field. The receptive fields of different cells overlap to cover the entire visual field. The cells in the visual cortex are sensitive to different features of the visual field like edges, colors, etc.\n",
    "\n",
    "CNN受到人脑结构的启发。人脑有一个负责处理视觉信息的视觉皮层。视觉皮层有一个对视觉场的特定区域敏感的小区域。这个区域被称为感受野。不同细胞的感受野重叠，覆盖整个视觉场。视觉皮层的细胞对视觉场的不同特征敏感，如边缘、颜色等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs utilize a special type of layer, aptly named a convolutional layer, that makes them well-positioned to learn from image and image-like data. Regarding image data, CNNs can be used for many different computer vision tasks, such as image processing, classification, segmentation, and object detection.\n",
    "\n",
    "CNN 利用一种特殊类型的层，即卷积层，使其能够很好地学习图像和类似图像的数据。在图像数据方面，CNN 可用于许多不同的计算机视觉任务，如图像处理、分类、分割和物体检测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolutional layers are the foundation of CNN, as they contain the learned kernels (weights), which extract features that distinguish different images from one another—this is what we want for classification! As you interact with the convolutional layer, you will notice links between the previous layers and the convolutional layers. Each link represents a unique kernel, which is used for the convolution operation to produce the current convolutional neuron's output or activation map.\n",
    "\n",
    "卷积层是 CNN 的基础，因为它们包含了学习到的核（权重），这些核可以提取出区分不同图像的特征--这正是我们想要的分类功能！当你与卷积层交互时，你会注意到前几层与卷积层之间的链接。每个链接都代表一个独特的内核，用于卷积操作，生成当前卷积神经元的输出或激活图。\n",
    "\n",
    "The convolutional neuron performs an elementwise dot product with a unique kernel and the output of the previous layer's corresponding neuron. This will yield as many intermediate results as there are unique kernels. The convolutional neuron is the result of all of the intermediate results summed together with the learned bias.\n",
    "\n",
    "卷积神经元与唯一的内核和上一层相应神经元的输出进行元素点乘。有多少个独特的内核，就会产生多少个中间结果。卷积神经元是所有中间结果与学习偏置相加的结果。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://poloclub.github.io/cnn-explainer/assets/figures/convlayer_overview_demo.gif)\n",
    "\n",
    "For example, let's look at the first convolutional layer in the Tiny VGG architecture above. Notice that there are 10 neurons in this layer, but only 3 neurons in the previous layer. In the Tiny VGG architecture, convolutional layers are fully-connected, meaning each neuron is connected to every other neuron in the previous layer. Focusing on the output of the topmost convolutional neuron from the first convolutional layer, we see that there are 3 unique kernels when we hover over the activation map.\n",
    "\n",
    "例如，让我们来看看上述 Tiny VGG 架构中的第一个卷积层。请注意，这一层有 10 个神经元，而上一层只有 3 个神经元。在 Tiny VGG 架构中，卷积层是全连接的，这意味着每个神经元都与上一层中的其他神经元相连。我们将注意力集中在第一个卷积层最顶端卷积神经元的输出上，当我们将鼠标悬停在激活图上时，会发现有 3 个独特的内核。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of these kernels is a hyper-parameter specified by the designers of the network architecture. In order to produce the output of the convolutional neuron (activation map), we must perform an elementwise dot product with the output of the previous layer and the unique kernel learned by the network. In TinyVGG, the dot product operation uses a stride of 1, which means that the kernel is shifted over 1 pixel per dot product, but this is a hyperparameter that the network architecture designer can adjust to better fit their dataset. We must do this for all 3 kernels, which will yield 3 intermediate results.\n",
    "\n",
    "这些核的大小是网络架构设计人员指定的一个超参数。为了生成卷积神经元的输出（激活图），我们必须将上一层的输出与网络学习到的唯一核进行元素点乘。在 TinyVGG 中，点乘运算使用的跨距为 1，这意味着每次点乘时，内核都会移动 1 个像素，但这是一个超参数，网络架构设计师可以对其进行调整，以更好地适应自己的数据集。我们必须对所有 3 个内核都这样做，这将产生 3 个中间结果。\n",
    "\n",
    "![](https://poloclub.github.io/cnn-explainer/assets/figures/convlayer_detailedview_demo.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, an elementwise sum is performed containing all 3 intermediate results along with the bias the network has learned. After this, the resulting 2-dimensional tensor will be the activation map viewable on the interface above for the topmost neuron in the first convolutional layer. This same operation must be applied to produce each neuron's activation map.\n",
    "\n",
    "然后，再对所有 3 个中间结果以及网络学习到的偏置进行元素相加。之后，得到的二维张量将是第一个卷积层最顶层神经元的激活图，可在上述界面查看。在绘制每个神经元的激活图时，都必须执行相同的操作。\n",
    "\n",
    "With some simple math, we are able to deduce that there are 3 x 10 = 30 unique kernels, each of size 3x3, applied in the first convolutional layer. The connectivity between the convolutional layer and the previous layer is a design decision when building a network architecture, which will affect the number of kernels per convolutional layer. \n",
    "\n",
    "通过一些简单的数学运算，我们可以推断出第一卷积层中有 3 x 10 = 30 个独特的内核，每个内核的大小为 3x3。卷积层和上一层之间的连接是构建网络架构时的一个设计决定，这将影响每个卷积层的内核数量。！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # 需要的各种包\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision # 数据库模块\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# 数据预处理\n",
    "# 将training data转化成torch能够使用的DataLoader，这样可以方便使用batch进行训练\n",
    "torch.manual_seed(1) # reproducible 将随机数生成器的种子设置为固定值，这样，当调用时torch.rand(x)，结果将可重现\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 1 # 训练迭代次数\n",
    "BATCH_SIZE = 50 # 分块送入训练器\n",
    "LR = 0.001 # 学习率 learning rate\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist/', # 保存位置 若没有就新建\n",
    "    train=True, # training set\n",
    "    transform=torchvision.transforms.ToTensor(), # \n",
    "    # converts a PIL.Image or numpy.ndarray to torch.FloatTensor(C*H*W) in range(0.0,1.0)\n",
    "    download=True\n",
    ")\n",
    " \n",
    "test_data = torchvision.datasets.MNIST(root='./MNIST/')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果是普通的Tensor数据，想使用 torch_dataset = data.TensorDataset(data_tensor=x, target_tensor=y)\n",
    "# 将Tensor转换成torch能识别的dataset\n",
    "# 批训练， 50 samples, 1 channel, 28*28, (50, 1, 28 ,28)\n",
    "train_loader = data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    " \n",
    "test_x = Variable(torch.unsqueeze(test_data.test_data, dim=1), volatile=True).type(torch.FloatTensor)[:2000]/255.\n",
    "# torch.unsqueeze 返回一个新的张量，对输入的既定位置插入维度 1\n",
    " \n",
    "test_y = test_data.test_lables[:2000]\n",
    "# 数据预处理\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# 定义网络结构\n",
    "# 1）class CNN需要·继承·Module \n",
    "# 2）需要·调用·父类的构造方法：super(CNN, self).__init__()\n",
    "# 3）在Pytorch中激活函数Relu也算是一层layer\n",
    "# 4）需要·实现·forward()方法，用于网络的前向传播，而反向传播只需要·调用·Variable.backward()即可。\n",
    "# 输入的四维张量[N, C, H, W]\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # nn.Sequential一个有序的容器，神经网络模块将按照在传入构造器的顺序依次被添加到计算图中执行，\n",
    "        # 同时以神经网络模块为元素的有序字典也可以作为传入参数\n",
    "        # nn.Conv2d 二维卷积 先实例化再使用 在Pytorch的nn模块中，它是不需要你手动定义网络层的权重和偏置的\n",
    "        self.conv1 = nn.Sequential( #input shape (1,28,28)\n",
    "            nn.Conv2d(in_channels=1, #input height 必须手动提供 输入张量的channels数\n",
    "                      out_channels=16, #n_filter 必须手动提供 输出张量的channels数\n",
    "                      kernel_size=5, #filter size 必须手动提供 卷积核的大小 \n",
    "                      # 如果左右两个数不同，比如3x5的卷积核，那么写作kernel_size = (3, 5)，注意需要写一个tuple，而不能写一个列表（list）\n",
    "                      stride=1, #filter step 卷积核在图像窗口上每次平移的间隔，即所谓的步长\n",
    "                      padding=2 #con2d出来的图片大小不变 Pytorch与Tensorflow在卷积层实现上最大的差别就在于padding上\n",
    "            ), # output shape (16,28,28) 输出图像尺寸计算公式是唯一的 # O = （I - K + 2P）/ S +1\n",
    "            nn.ReLU(), # 分段线性函数，把所有的负值都变为0，而正值不变，即单侧抑制\n",
    "            nn.MaxPool2d(kernel_size=2) #2x2采样，28/2=14，output shape (16,14,14) maxpooling有局部不变性而且可以提取显著特征的同时降低模型的参数，从而降低模型的过拟合\n",
    "        ) \n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16, 32, 5, 1, 2), #output shape (32,7,7)\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.MaxPool2d(2))\n",
    "        # 因上述几层网络处理后的output为[32,7,7]的tensor，展开即为7*7*32的一维向量，接上一层全连接层，最终output_size应为10，即识别出来的数字总类别数\n",
    "        # 在二维图像处理的任务中，全连接层的输入与输出一般都设置为二维张量，形状通常为[batch_size, size]\n",
    "        self.out = nn.Linear(32*7*7, 10) # 全连接层 7*7*32, num_classes\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # 卷一次\n",
    "        x = self.conv2(x) # 卷两次\n",
    "        x = x.view(x.size(0), -1) #flat (batch_size, 32*7*7) \n",
    "        # 将前面多维度的tensor展平成一维 x.size(0)指batchsize的值\n",
    "        # view()函数的功能根reshape类似，用来转换size大小\n",
    "        output = self.out(x) # fc out全连接层 分类器\n",
    "        return output\n",
    "# 定义网络结构\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看网络结构\n",
    "cnn = CNN()\n",
    "print(cnn) # 使用print(cnn)可以看到网络的结构详细信息，可以看到ReLU()也是一层layer\n",
    "# 查看网络结构\n",
    " \n",
    " \n",
    "# 训练 需要特别指出的是记得每次反向传播前都要清空上一次的梯度，optimizer.zero_grad()\n",
    "# optimizer 可以指定程序优化特定的选项，例如学习速率，权重衰减等\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR) # torch.optim是一个实现了多种优化算法的包\n",
    " \n",
    "# loss_fun CrossEntropyLoss 交叉熵损失\n",
    "# 信息量：它是用来衡量一个事件的不确定性的；一个事件发生的概率越大，不确定性越小，则它所携带的信息量就越小。\n",
    "# 熵：它是用来衡量一个系统的混乱程度的，代表一个系统中信息量的总和；信息量总和越大，表明这个系统不确定性就越大。\n",
    "# 交叉熵：它主要刻画的是实际输出（概率）与期望输出（概率）的距离，也就是交叉熵的值越小，两个概率分布就越接近\n",
    "loss_func = nn.CrossEntropyLoss() # 该损失函数结合了nn.LogSoftmax()和nn.NLLLoss()两个函数 适用于分类\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "for epoch in range(EPOCH):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        batch_x = Variable(x)\n",
    "        batch_y = Variable(y)\n",
    "        output = cnn(batch_x) # 输入训练数据\n",
    "        loss = loss_func(output, batch_y) # 计算误差 #　实际输出，　期望输出\n",
    "        optimizer.zero_grad() # 清空上一次梯度\n",
    "        loss.backward() # 误差反向传递 只需要调用.backward()即可\n",
    "        optimizer.step() # cnn的优化器参数更新\n",
    "# 训练\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果\n",
    "# cnn.eval()\n",
    "test_output = cnn(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "# torch.max(input, dim)函数  \n",
    "# torch.max(test_output, 1)[1]  取出来indices 每行最大值的索引\n",
    "# 输入 input是softmax函数输出的一个tensor  \n",
    "# 输入 dim是max函数索引的维度0/1，0是每列的最大值，1是每行的最大值\n",
    "# 输出 函数会返回两个tensor，第一个tensor是每行的最大值；第二个tensor是每行最大值的索引。\n",
    "# squeeze()函数的功能是：从矩阵shape中，去掉维度为1的。例如一个矩阵是的shape是（5， 1），使用过这个函数后，结果为（5，）。\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10], 'real number')\n",
    "# 预测结果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
